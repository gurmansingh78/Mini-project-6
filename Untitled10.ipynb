{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKPm4BlJser9owS7kGZ7fa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurmansingh78/Mini-project-6/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1.Create a file that contains 1000 lines of random strings."
      ],
      "metadata": {
        "id": "fsF2chWAQxy8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BxMTdoS-QW3z"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "# Function to generate a random string of a given length\n",
        "def generate_random_string(length=12):\n",
        "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
        "\n",
        "# Generate 1000 lines of random strings\n",
        "random_strings = [generate_random_string() for _ in range(1000)]\n",
        "\n",
        "# Write to a file\n",
        "with open(\"random_strings_1000.txt\", \"w\") as file:\n",
        "    file.write(\"\\n\".join(random_strings))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2.Create a file that contains multiple lines of random strings and file size must be 5 MB."
      ],
      "metadata": {
        "id": "yWvrdx4zRm4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_string(length=100):\n",
        "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
        "\n",
        "target_size = 5 * 1024 * 1024  # 5 MB in bytes\n",
        "output_file = \"random_5MB.txt\"\n",
        "\n",
        "with open(output_file, \"w\") as f:\n",
        "    total_written = 0\n",
        "    while total_written < target_size:\n",
        "        line = generate_random_string(95) + \"\\n\"  # 95 chars + 1 newline = 96 bytes\n",
        "        f.write(line)\n",
        "        total_written += len(line)\n",
        "\n",
        "# Optionally, print the actual size\n",
        "print(f\"File '{output_file}' created with size: {os.path.getsize(output_file)} bytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvBNWaq_Rvq4",
        "outputId": "94045684-5e1d-48d9-9ced-5391864b4ff4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'random_5MB.txt' created with size: 5242944 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3.Create 10 files that contains multiple lines of random strings and file size of each file must be 5 MB."
      ],
      "metadata": {
        "id": "8HvLG8E9R4KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_string(length=95):\n",
        "    \"\"\"Generates a random string of fixed length.\"\"\"\n",
        "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
        "\n",
        "def create_file_with_random_strings(filename, target_size_bytes):\n",
        "    \"\"\"Creates a single file with random strings totaling ~target_size_bytes.\"\"\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        total_written = 0\n",
        "        while total_written < target_size_bytes:\n",
        "            line = generate_random_string() + \"\\n\"\n",
        "            f.write(line)\n",
        "            total_written += len(line)\n",
        "\n",
        "# Parameters\n",
        "num_files = 10\n",
        "target_size = 5 * 1024 * 1024  # 5 MB in bytes\n",
        "\n",
        "# Generate files\n",
        "for i in range(1, num_files + 1):\n",
        "    filename = f\"random_file_{i}.txt\"\n",
        "    create_file_with_random_strings(filename, target_size)\n",
        "    print(f\"Created: {filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUZ1inMMSG6A",
        "outputId": "c77457af-09fc-44a8-e787-87b83779e694"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created: random_file_1.txt\n",
            "Created: random_file_2.txt\n",
            "Created: random_file_3.txt\n",
            "Created: random_file_4.txt\n",
            "Created: random_file_5.txt\n",
            "Created: random_file_6.txt\n",
            "Created: random_file_7.txt\n",
            "Created: random_file_8.txt\n",
            "Created: random_file_9.txt\n",
            "Created: random_file_10.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4.Create 5 files of size 1GB, 2GB, 3GB, 4GB and 5GB; file contains multiple lines of random strings."
      ],
      "metadata": {
        "id": "84gbOdEqSVDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_string(length=95):\n",
        "    \"\"\"Generate a random string of fixed length (excluding newline).\"\"\"\n",
        "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
        "\n",
        "def create_large_file(filename, target_size_bytes):\n",
        "    \"\"\"Creates a file filled with random strings totaling ~target_size_bytes.\"\"\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        total_written = 0\n",
        "        while total_written < target_size_bytes:\n",
        "            line = generate_random_string() + \"\\n\"  # ~96 bytes\n",
        "            f.write(line)\n",
        "            total_written += len(line)\n",
        "    print(f\"Created {filename}: {os.path.getsize(filename) / (1024**3):.2f} GB\")\n",
        "\n",
        "# File sizes in GB\n",
        "sizes_gb = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Create each file\n",
        "for size in sizes_gb:\n",
        "    filename = f\"random_file_{size}GB.txt\"\n",
        "    size_in_bytes = size * 1024**3  # Convert GB to bytes\n",
        "    create_large_file(filename, size_in_bytes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "F8S63CHFSfIF",
        "outputId": "4be9df25-530d-4105-8705-afb9fc82c6d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created random_file_1GB.txt: 1.00 GB\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2670372793>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"random_file_{size}GB.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msize_in_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m  \u001b[0;31m# Convert GB to bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mcreate_large_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_in_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-2670372793>\u001b[0m in \u001b[0;36mcreate_large_file\u001b[0;34m(filename, target_size_bytes)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtotal_written\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mtotal_written\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_size_bytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_random_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m  \u001b[0;31m# ~96 bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mtotal_written\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2670372793>\u001b[0m in \u001b[0;36mgenerate_random_string\u001b[0;34m(length)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_random_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"\"\"Generate a random string of fixed length (excluding newline).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_letters\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_large_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/random.py\u001b[0m in \u001b[0;36mchoices\u001b[0;34m(self, population, weights, cum_weights, k)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mfloor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_floor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                 \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.0\u001b[0m    \u001b[0;31m# convert to float for a small speed improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_repeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mcum_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_accumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/random.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mfloor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_floor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                 \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.0\u001b[0m    \u001b[0;31m# convert to float for a small speed improvement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_repeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mcum_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_accumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5.Convert all the files of Q4 into upper case one by one."
      ],
      "metadata": {
        "id": "CRF-0PHrUHwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def convert_file_to_uppercase(input_file, output_file):\n",
        "    \"\"\"Converts all text in the input file to uppercase and writes to output file.\"\"\"\n",
        "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            outfile.write(line.upper())\n",
        "    print(f\"Converted: {input_file} → {output_file}\")\n",
        "\n",
        "# File sizes to process (in GB)\n",
        "sizes_gb = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Process each file\n",
        "for size in sizes_gb:\n",
        "    input_filename = f\"random_file_{size}GB.txt\"\n",
        "    output_filename = f\"random_file_{size}GB_upper.txt\"\n",
        "    convert_file_to_uppercase(input_filename, output_filename)"
      ],
      "metadata": {
        "id": "L0FuoaSEUMyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6.Convert all the files of Q4 into upper case parallel using multi-threading."
      ],
      "metadata": {
        "id": "nSpRJHNuUoQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def convert_file_to_uppercase(input_file, output_file):\n",
        "    \"\"\"Reads from input_file line by line, converts to uppercase, and writes to output_file.\"\"\"\n",
        "    print(f\"Starting conversion: {input_file}\")\n",
        "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            outfile.write(line.upper())\n",
        "    print(f\"Finished conversion: {input_file}\")\n",
        "\n",
        "# File sizes to process (in GB)\n",
        "sizes_gb = [1, 2, 3, 4, 5]\n",
        "threads = []\n",
        "\n",
        "# Create and start threads for each file\n",
        "for size in sizes_gb:\n",
        "    input_filename = f\"random_file_{size}GB.txt\"\n",
        "    output_filename = f\"random_file_{size}GB_upper.txt\"\n",
        "    thread = threading.Thread(target=convert_file_to_uppercase, args=(input_filename, output_filename))\n",
        "    thread.start()\n",
        "    threads.append(thread)\n",
        "\n",
        "# Wait for all threads to finish\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "\n",
        "print(\"All files converted to uppercase.\")"
      ],
      "metadata": {
        "id": "meIkI49KU4l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q7.WAP to automatically download IO images of cat from \"Google Images\". [Hint: Find the package frompypi.org and use it]"
      ],
      "metadata": {
        "id": "3SFxV63UU7xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "API_KEY = \"YOUR_API_KEY\"\n",
        "CSE_ID = \"YOUR_CSE_ID\"\n",
        "\n",
        "def google_search(search_term, api_key, cse_id, num=10):\n",
        "    search_url = \"https://www.googleapis.com/customsearch/v1\"\n",
        "    params = {\n",
        "        \"q\": search_term,\n",
        "        \"cx\": cse_id,\n",
        "        \"key\": api_key,\n",
        "        \"searchType\": \"image\",\n",
        "        \"num\": num,\n",
        "    }\n",
        "    response = requests.get(search_url, params=params)\n",
        "    return response.json()\n",
        "\n",
        "def download_images(data, folder=\"cat_images\"):\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "    for i, item in enumerate(data.get(\"items\", [])):\n",
        "        img_url = item[\"link\"]\n",
        "        try:\n",
        "            img_data = requests.get(img_url).content\n",
        "            with open(os.path.join(folder, f\"cat_{i+1}.jpg\"), \"wb\") as f:\n",
        "                f.write(img_data)\n",
        "            print(f\"Downloaded image {i+1}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not download image {i+1}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = google_search(\"cat\", API_KEY, CSE_ID, num=10)\n",
        "    download_images(results)\n"
      ],
      "metadata": {
        "id": "8jwnpN9lVMFv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q8.WAP to automatically download 10 videos of \"Machine Learning\" from \"Youtube.com\". [Hint: Find thepackage from pypi.org and use it]"
      ],
      "metadata": {
        "id": "a-DmWvRLVcWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rOWLIeUYJtF",
        "outputId": "bcd74fa0-2a9c-4f12-d34d-b4662cd9fbb0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import Search, YouTube\n",
        "import os\n",
        "\n",
        "SEARCH_QUERY = \"Machine Learning\"\n",
        "MAX_VIDEOS = 10\n",
        "DOWNLOAD_FOLDER = \"ml_videos_pytube\"\n",
        "\n",
        "def download_videos():\n",
        "    if not os.path.exists(DOWNLOAD_FOLDER):\n",
        "        os.makedirs(DOWNLOAD_FOLDER)\n",
        "\n",
        "    search = Search(SEARCH_QUERY)\n",
        "    videos = search.results[:MAX_VIDEOS]\n",
        "\n",
        "    for i, video in enumerate(videos):\n",
        "        try:\n",
        "            print(f\"Downloading {i+1}: {video.title}\")\n",
        "            stream = video.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
        "            stream.download(DOWNLOAD_FOLDER)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    download_videos()"
      ],
      "metadata": {
        "id": "tp2FgsGpVuE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q9.Convert all the videos of Q8 and convert it to audio. [Hint: Find the package from pypi.org and use it]"
      ],
      "metadata": {
        "id": "sv3EJeuBVx3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yt-dlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIagbyCuX9tS",
        "outputId": "c56e2448-2b6f-4820-a71c-60fc61f8e744"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.6.9-py3-none-any.whl.metadata (174 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/174.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.6.9-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.6.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Folder to save audio files\n",
        "AUDIO_FOLDER = \"ml_audio\"\n",
        "os.makedirs(AUDIO_FOLDER, exist_ok=True)\n",
        "\n",
        "# List of 10 YouTube video URLs (replace or add more as needed)\n",
        "video_urls = [\n",
        "    \"https://www.youtube.com/watch?v=GwIo3gDZCVQ\",\n",
        "    \"https://www.youtube.com/watch?v=aircAruvnKk\",\n",
        "    \"https://www.youtube.com/watch?v=KTeVOb8gaD4\",\n",
        "    \"https://www.youtube.com/watch?v=1vsmaEfbnoE\",\n",
        "    \"https://www.youtube.com/watch?v=8rXD5-xhemo\",\n",
        "    \"https://www.youtube.com/watch?v=ukzFI9rgwfU\",\n",
        "    \"https://www.youtube.com/watch?v=i_LwzRVP7bg\",\n",
        "    \"https://www.youtube.com/watch?v=4b5d3muPQmA\",\n",
        "    \"https://www.youtube.com/watch?v=Gv9_4yMHFhI\"\n",
        "]\n",
        "\n",
        "# Function to convert video to audio\n",
        "def convert_to_audio(url):\n",
        "    try:\n",
        "        command = [\n",
        "            \"yt-dlp\",\n",
        "            \"--extract-audio\",\n",
        "            \"--audio-format\", \"mp3\",\n",
        "            \"--output\", os.path.join(AUDIO_FOLDER, \"%(title)s.%(ext)s\"),\n",
        "            url\n",
        "        ]\n",
        "        subprocess.run(command, check=True)\n",
        "        print(f\"✅ Converted: {url}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"❌ Error converting {url}: {e}\")\n",
        "\n",
        "# Process all videos\n",
        "def main():\n",
        "    print(f\"🔄 Starting conversion of {len(video_urls)} videos to MP3...\")\n",
        "    for url in video_urls:\n",
        "        convert_to_audio(url)\n",
        "    print(f\"\\n🎉 All videos converted. Files saved in '{AUDIO_FOLDER}'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "3eDPLVRPWREb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q10.Create an automated pipeline using multi-threading for:\n",
        "# \"Automatic Download of 100 Videos from YouTube\" \"Convert it to Audio\"."
      ],
      "metadata": {
        "id": "LIsMk66uWcn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import concurrent.futures\n",
        "from time import time\n",
        "\n",
        "# Folder to save audio files\n",
        "DOWNLOAD_FOLDER = \"yt_audio_100\"\n",
        "MAX_THREADS = 8  # You can increase this based on your system capability\n",
        "\n",
        "# List of YouTube video URLs (100 video links can go here)\n",
        "video_urls = [\n",
        "    # -- Add your 100 video links below --\n",
        "    \"https://www.youtube.com/watch?v=Gv9_4yMHFhI\",\n",
        "    \"https://www.youtube.com/watch?v=ukzFI9rgwfU\",\n",
        "    # ... up to 100 links\n",
        "]\n",
        "\n",
        "# Ensure output directory exists\n",
        "if not os.path.exists(DOWNLOAD_FOLDER):\n",
        "    os.makedirs(DOWNLOAD_FOLDER)\n",
        "\n",
        "# Function to download and convert a single video\n",
        "def process_video(url):\n",
        "    try:\n",
        "        print(f\"Starting download: {url}\")\n",
        "        command = [\n",
        "            \"yt-dlp\",\n",
        "            \"--extract-audio\",\n",
        "            \"--audio-format\", \"mp3\",\n",
        "            \"-o\", os.path.join(DOWNLOAD_FOLDER, \"%(title)s.%(ext)s\"),\n",
        "            url\n",
        "        ]\n",
        "        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        return f\"✅ Success: {url}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ Failed: {url} | Error: {e}\"\n",
        "\n",
        "# Main function to run multithreaded pipeline\n",
        "def run_pipeline(urls):\n",
        "    start_time = time()\n",
        "    print(f\"\\n🚀 Starting download/conversion of {len(urls)} videos...\\n\")\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
        "        results = list(executor.map(process_video, urls))\n",
        "\n",
        "    for result in results:\n",
        "        print(result)\n",
        "\n",
        "    print(f\"\\n✅ All tasks completed in {round(time() - start_time, 2)} seconds.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_pipeline(video_urls)\n"
      ],
      "metadata": {
        "id": "7g3Yf7cuWmla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q11.Create an automated pipeline using multi-threading for: \"Automatic Download of 500 images of Dog from Googlelmages\" \"Rescale it to 50%\""
      ],
      "metadata": {
        "id": "jbT0nFoHWtuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install icrawler pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-KICO4HXnQ6",
        "outputId": "5489e6ea-6f84-485c-f356-2dc03903778c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icrawler\n",
            "  Downloading icrawler-0.6.10-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from icrawler) (4.13.4)\n",
            "Collecting bs4 (from icrawler)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from icrawler) (5.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from icrawler) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from icrawler) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from icrawler) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2025.4.26)\n",
            "Downloading icrawler-0.6.10-py3-none-any.whl (36 kB)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4, icrawler\n",
            "Successfully installed bs4-0.0.2 icrawler-0.6.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from icrawler.builtin import GoogleImageCrawler\n",
        "from PIL import Image\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Settings\n",
        "NUM_IMAGES = 500\n",
        "MAX_THREADS = 8\n",
        "INPUT_FOLDER = 'dog_images_raw'\n",
        "OUTPUT_FOLDER = 'dog_images_rescaled'\n",
        "\n",
        "# Step 1: Download images using icrawler\n",
        "def download_images():\n",
        "    if not os.path.exists(INPUT_FOLDER):\n",
        "        os.makedirs(INPUT_FOLDER)\n",
        "\n",
        "    print(f\"📥 Downloading {NUM_IMAGES} dog images...\")\n",
        "    crawler = GoogleImageCrawler(storage={'root_dir': INPUT_FOLDER})\n",
        "    crawler.crawl(keyword='dog', max_num=NUM_IMAGES, file_idx_offset=0)\n",
        "\n",
        "# Step 2: Rescale image to 50%\n",
        "def rescale_image(img_path):\n",
        "    try:\n",
        "        with Image.open(img_path) as img:\n",
        "            new_size = (img.width // 2, img.height // 2)\n",
        "            img_resized = img.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "            if not os.path.exists(OUTPUT_FOLDER):\n",
        "                os.makedirs(OUTPUT_FOLDER)\n",
        "\n",
        "            base_name = os.path.basename(img_path)\n",
        "            output_path = os.path.join(OUTPUT_FOLDER, base_name)\n",
        "            img_resized.save(output_path)\n",
        "            return f\"✅ Rescaled: {base_name}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ Failed: {img_path} | Error: {e}\"\n",
        "\n",
        "# Multithreaded rescaling\n",
        "def rescale_all_images():\n",
        "    image_files = glob(os.path.join(INPUT_FOLDER, '*'))\n",
        "    print(f\"📏 Rescaling {len(image_files)} images to 50%...\")\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
        "        for result in tqdm(executor.map(rescale_image, image_files), total=len(image_files)):\n",
        "            pass  # tqdm handles progress; remove 'pass' to print result logs if needed\n",
        "\n",
        "# Main pipeline\n",
        "def main():\n",
        "    download_images()\n",
        "    rescale_all_images()\n",
        "    print(f\"\\n🎉 Done! Images saved in '{OUTPUT_FOLDER}'.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb2LddGqW_TH",
        "outputId": "97103a12-8ce9-4dc1-a05e-a5ea3f71f017"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Downloading 500 dog images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread parser-001:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/icrawler/parser.py\", line 93, in worker_exec\n",
            "    for task in self.parse(response, **kwargs):\n",
            "TypeError: 'NoneType' object is not iterable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📏 Rescaling 1 images to 50%...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1204.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎉 Done! Images saved in 'dog_images_rescaled'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXpblTHKYqP7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}